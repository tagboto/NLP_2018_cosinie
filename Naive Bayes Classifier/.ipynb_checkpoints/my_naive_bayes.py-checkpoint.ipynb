{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Assignment 1\n",
    "## My Naive Bayes Classifier \n",
    "\n",
    "Name: Zoe Tagboto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Below we define a function gathers the reviews from the file, cleans each line, and puts them in a dictionary based on the class of each review </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-174-9950a0a8d5d9>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-174-9950a0a8d5d9>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    all_classes[val].append(re.sub([0-9]+,\"\",review[:-1].split())\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def read_file_to_dict(*filenames):\n",
    "    all_classes = {}\n",
    "    for filename in filenames:\n",
    "        for line in open(filename):\n",
    "            clean_line = re.sub(r\"[\"\"\\n\\t!'';:&*():?%$#+]\",\"\",line.lower())\n",
    "            review = re.sub(r\"[/,.-]\",\" \",clean_line)\n",
    "            val = int(review[-1][-1])\n",
    "            if val in all_classes:\n",
    "                all_classes[val].append(re.sub([0-9]+,\"\",review[:-1].split())\n",
    "            else:\n",
    "                all_classes[val] = [re.sub([0-9]+,\"\",review[:-1].split())]\n",
    "    random.shuffle(all_classes[0])\n",
    "    random.shuffle(all_classes[1])\n",
    "    return all_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Below we define the function to split our data into test and training sets</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_train_and_test(all_classes):\n",
    "    total_amount = len(all_classes[0])\n",
    "    train_amount = round(0.8* total_amount)\n",
    "    \n",
    "    test_classes =  {0:all_classes[0][train_amount:total_amount],1:all_classes[1][train_amount:total_amount]}\n",
    "    train_classes = {0:all_classes[0][0:train_amount],1:all_classes[1][0:train_amount]}\n",
    "    \n",
    "    return test_classes, train_classes\n",
    "                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Here we define a function that creates a dictionary for each class that contains each word in the class and how often they are used </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def class_dict(all_classes, index):\n",
    "    words = list(chain.from_iterable(all_classes[index]))\n",
    "    type_class = Counter(words)\n",
    "\n",
    "    return(type_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Here we calculate the log prior which uses the following equation </i>\n",
    "\n",
    "$$\\log \\frac{N_c}{N_{doc}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_prior(train_classes):\n",
    "    pos_log_prior = np.log(len(train_classes[0])\n",
    "                         /(len(train_classes[0])+len(train_classes[1])))\n",
    "    neg_log_prior = np.log(len(train_classes[1])/(len(train_classes[0])+len(train_classes[1])))\n",
    "    \n",
    "    return pos_log_prior, neg_log_prior\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Below we define a function that creates a dictionary with a count of every word that occurs in the file </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def complete_vocab_list(pos_dict, neg_dict):\n",
    "    total_dict = pos_dict.copy()   # start with x's keys and values\n",
    "    for key in neg_dict:\n",
    "        if key in total_dict:\n",
    "            total_dict[key] += neg_dict[key]\n",
    "        else:\n",
    "            total_dict[key] = neg_dict[key]\n",
    "            \n",
    "       \n",
    "    return total_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Below we define the function to calculate the logLikelihood using the following equation:</i>\n",
    "$$\\log \\frac{count(w_{i}, c)+1}{\\sum_{w\\in v}^{}(count(w, c)+1)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_likelihood_class(total_dict,Class, word):\n",
    "    if word in Class.keys():\n",
    "        numerator = Class[word] +1\n",
    "    else:\n",
    "        numerator = 1   \n",
    "    \n",
    "    \n",
    "    denominator= len(set(total_dict.keys()) - set(Class.keys()))+len(Class.keys())\n",
    "    denominator+= sum(Class.values())\n",
    "    \n",
    "    log_likelihood =  np.log(numerator/denominator)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return log_likelihood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(total_dict, pos_class, neg_class):\n",
    "    likelihood_dict = {}\n",
    "    for key in total_dict.keys():\n",
    "        likelihood_dict[key]=(log_likelihood_class(total_dict,pos_class, key),log_likelihood_class(total_dict,neg_class, key))\n",
    "        \n",
    "    return likelihood_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(test_classes):     \n",
    "    percent_correct = 0 \n",
    "    total = 0\n",
    "    \n",
    "    for line in test_classes[0]:\n",
    "        is_pos = 0 \n",
    "        is_neg = 0\n",
    "        total+=1\n",
    "        for word in line: \n",
    "            if word in likelihood_dict.keys():\n",
    "                is_pos +=likelihood_dict[word][0]\n",
    "                is_neg +=likelihood_dict[word][1]\n",
    "        if is_neg> is_pos:\n",
    "            percent_correct+=1\n",
    "            \n",
    "    for line in test_classes[1]:\n",
    "        is_pos = 0 \n",
    "        is_neg = 0\n",
    "        total+=1\n",
    "        for word in line: \n",
    "            if word in likelihood_dict.keys():\n",
    "                is_pos +=likelihood_dict[word][0]\n",
    "                is_neg +=likelihood_dict[word][1]\n",
    "        if is_neg< is_pos:\n",
    "            percent_correct+=1\n",
    "    accuracy = (percent_correct/total)*100\n",
    "    print(\"my accuracy is\", accuracy, \"woo hoo!\")\n",
    "    print(\"the total is\", total)\n",
    "    print(\"correct\", percent_correct)\n",
    "                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "all_classes = read_file_to_dict('amazon_cells_labelled.txt', 'imdb_labelled.txt','yelp_labelled.txt')\n",
    "train_classes, test_classes = split_train_and_test(all_classes)\n",
    "pos_class = class_dict(train_classes,1)\n",
    "neg_class = class_dict(train_classes,0)\n",
    "total_dict = complete_vocab_list(pos_class, neg_class)\n",
    "pos_log_prior, neg_log_prior = log_prior(train_classes)\n",
    "likelihood_dict  = train(total_dict, pos_class, neg_class)\n",
    "test(test_classes)\n",
    "\n",
    "import collections\n",
    "collections.OrderedDict(sorted(likelihood_dict.items()))\n",
    "#sorted(likelihood_dict.iterkeys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
