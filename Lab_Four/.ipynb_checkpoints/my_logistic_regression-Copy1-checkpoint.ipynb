{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing \n",
    "\n",
    "## Assignment 4\n",
    "\n",
    "### My Logistic Regression Classifier\n",
    "\n",
    "### Name: Zoe Tagboto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_list_cleaned(*filenames):\n",
    "    labels =[]\n",
    "    reviews =[]\n",
    "    all_classes = {}\n",
    "    for filename in filenames:\n",
    "        for line in open(filename):\n",
    "            r2 = re.compile(r'[^a-zA-Z0-9]', re.MULTILINE)\n",
    "            s = r2.sub(' ', line)\n",
    "            val = int(s[-2])\n",
    "            \n",
    "            labels.append(val)\n",
    "            reviews.append(s[:-2])\n",
    "            \n",
    "    return reviews, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_list_uncleaned(*filenames):\n",
    "    labels =[]\n",
    "    reviews = []\n",
    "    for filename in filenames:\n",
    "        for line in open(filename): \n",
    "            val = int(line[-2])\n",
    "            \n",
    "            reviews.append(line.lower()[:-2])\n",
    "            \n",
    "            labels.append(val)\n",
    "            \n",
    "    return reviews, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_train(reviews,labels, Boolean):\n",
    "\n",
    "    #N-gram model that comes up with features or occurances of words\n",
    "    if Boolean == True:\n",
    "        count_vect = CountVectorizer(stop_words='english')\n",
    "        tf_transform = TfidfTransformer()\n",
    "    else:\n",
    "        count_vect = CountVectorizer( strip_accents=None, lowercase=False)\n",
    "        tf_transform = TfidfTransformer(use_idf=False)\n",
    "    X_train_counts = count_vect.fit_transform(r for r in reviews)\n",
    "    \n",
    "    # This is to scale down impact of tkens that occur very frequently and arent\n",
    "    #very informative.\n",
    "    #Term Frequency time Inverse Document Frequency\n",
    "\n",
    "    X_train_counts = count_vect.fit_transform(r for r in reviews)\n",
    "    \n",
    "    # This is to scale down impact of tkens that occur very frequently and arent\n",
    "    #very informative.\n",
    "    #Term Frequency time Inverse Document Frequency\n",
    "    \n",
    "    X_train_tf = tf_transform.fit_transform(X_train_counts)\n",
    "    \n",
    "    #splitting data into test and training sets\n",
    "    X_train, X_test, Y_train, Y_test =train_test_split(X_train_tf,labels, random_state = 35 , train_size =0.90, test_size =0.10)\n",
    " \n",
    "\n",
    "    #MAKING THE MODEL\n",
    "    lrn = LogisticRegression()\n",
    "    model = lrn.fit(X_train, Y_train)\n",
    "    #array.reshape(-1, 1)\n",
    "    \n",
    "    return lrn, tf_transform, count_vect, model, X_test, Y_test\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " def lr_test(test_file,reviews,labels, Boolean):\n",
    "    lrn,tf_transform, count_vect, model, X_test, Y_test = lr_train(reviews,labels, Boolean)\n",
    "   \n",
    "  \n",
    "    \n",
    "    #Now using the test set I need to know if I'm right\n",
    "    test_data = []\n",
    "    for line in open(test_file):\n",
    "        r2 = re.compile(r'[^a-zA-Z0-9]', re.MULTILINE)\n",
    "        s = r2.sub(' ', line)\n",
    "        test_data.append(s)\n",
    "    \n",
    "    if Boolean == True:\n",
    "        test_data = stemming(test_data)\n",
    "        test_data = lemming(test_data)\n",
    "        \n",
    "    else:\n",
    "        test_data = test_data\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Making sentiment classification\n",
    "    for i in range (len(test_data)):\n",
    "        X_pred_counts = count_vect.transform(test_data)\n",
    "        X_pred_tf = tf_transform.transform(X_pred_counts)\n",
    "        predictions = lrn.predict(X_pred_tf)\n",
    "                \n",
    "                        \n",
    "    #Evaluating the model using the classification report function form sklearn\n",
    "\n",
    "    predicted = model.predict(X_test)    \n",
    "    print(\"The accuracy of this test is: \" ,accuracy_score(Y_test, predicted)*100) \n",
    "\n",
    "    print(\"This is a more detailed report of the classifiers performance: \\n\" ,classification_report(Y_test, predicted))\n",
    "    \n",
    "    return(predictions,\"\\n\")                                                \n",
    "                                                     \n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(reviews):\n",
    "    lancaster_stemmer = LancasterStemmer()\n",
    "    n_reviews = []\n",
    "    for review in reviews:\n",
    "        n_reviews.append(' '.join(lancaster_stemmer.stem(token)for token in nltk.word_tokenize(review)))\n",
    "    return(n_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemming(reviews):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    n_reviews = []\n",
    "    for review in reviews:\n",
    "        n_reviews.append(' '.join(wordnet_lemmatizer.lemmatize(token)for token in nltk.word_tokenize(review)))\n",
    "    return(n_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_LR():\n",
    "    reviews, labels = read_file_to_list_cleaned('amazon_cells_labelled.txt', 'imdb_labelled.txt','yelp_labelled.txt')\n",
    "    reviews = stemming(reviews)\n",
    "    reviews = lemming(reviews)\n",
    "    lr_test('test_sentences2.txt',reviews, labels,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results():\n",
    "    reviews, labels = read_file_to_list_cleaned('amazon_cells_labelled.txt', 'imdb_labelled.txt','yelp_labelled.txt')\n",
    "    reviews = stemming(reviews)\n",
    "    reviews = lemming(reviews)\n",
    "\n",
    "    predictions = naiveBayes(reviews,labels,'test_sentences2.txt')\n",
    "    \n",
    "\n",
    "    # write to file to gage my accuracy\n",
    "    with open(\"normalized_results.txt\", \"w+\") as file:\n",
    "        file.write(str(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this test is:  82.33333333333334\n",
      "This is a more detailed report of the classifiers performance: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.81      0.82       154\n",
      "          1       0.80      0.84      0.82       146\n",
      "\n",
      "avg / total       0.82      0.82      0.82       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "normalized_LR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalized_LR():\n",
    "    reviews, labels = read_file_to_list_uncleaned('amazon_cells_labelled.txt', 'imdb_labelled.txt','yelp_labelled.txt')\n",
    "    #print(reviews,labels)\n",
    "    lr_test('test_sentences2.txt',reviews, labels, False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this test is:  77.66666666666666\n",
      "This is a more detailed report of the classifiers performance: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.78      0.78       154\n",
      "          1       0.77      0.77      0.77       146\n",
      "\n",
      "avg / total       0.78      0.78      0.78       300\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(classifier, version, predictL):\n",
    "    file_name = open(\"results-\"+classifier+\"-\"+version+\".txt\", w)\n",
    "    #file_name.write(\"Ouput: \"+\"\\n\")\n",
    "    \n",
    "    for label in predictL[0]:\n",
    "        file_name.write(str(label)+\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    classifier =sys.argv[1]\n",
    "    version = sys.argv[2]\n",
    "    file = sys.argv[3]\n",
    "       \n",
    "    if classifier == \"nb\" and version == \"u\":\n",
    "        predictL  = testNaiveBayes_B(file)\n",
    "    elif classifier == \"nb\" and version == \"n\":\n",
    "        predictL = testNaiveBayes_A(file)\n",
    "    elif classifier == \"lr\" and version == \"n\":\n",
    "        predictL = testNormLR_A(file)\n",
    "    elif classifier == \"lr\" and version == \"u\":\n",
    "         predictL = testUnNormLR_B(file)\n",
    "    else:\n",
    "        print(\"Kindly check your syntax or input the right cominations\")\n",
    "        \n",
    "        sys.exit()\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    classifier =sys.argv[1]\n",
    "    version = sys.argv[2]\n",
    "    file = sys.argv[3]\n",
    "       \n",
    "    if classifier == \"nb\" and version == \"u\":\n",
    "        predicions  = testNaiveBayes_B(file)\n",
    "    elif classifier == \"nb\" and version == \"n\":\n",
    "        predictions = testNaiveBayes_A(file)\n",
    "    elif classifier == \"lr\" and version == \"n\":\n",
    "        predictions = testNormLR_A(file)\n",
    "    elif classifier == \"lr\" and version == \"u\":\n",
    "         predictions = testUnNormLR_B(file)\n",
    "    else:\n",
    "        print(\"Kindly check your syntax or input the right cominations\")\n",
    "        \n",
    "        sys.exit()\n",
    "        \n",
    "    \n",
    "    write_results(classifier, version,predictL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
