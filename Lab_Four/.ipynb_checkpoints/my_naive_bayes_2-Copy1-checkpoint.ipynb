{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing \n",
    "\n",
    "## Assignment 4\n",
    "\n",
    "### My Naive Bayes Classifier 2\n",
    "\n",
    "### Name: Zoe Tagboto\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all the libraries used to make my classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Below we define a function gathers the reviews from the file, cleans each line, and puts them into two lists based on the class of each review </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_list_cleaned(*filenames):\n",
    "    labels =[]\n",
    "    reviews =[]\n",
    "    all_classes = {}\n",
    "    for filename in filenames:\n",
    "        for line in open(filename):\n",
    "            r2 = re.compile(r'[^a-zA-Z0-9]', re.MULTILINE)\n",
    "            s = r2.sub(' ', line)\n",
    "            #newS = s.lower()\n",
    "            val = int(s[-2])\n",
    "            \n",
    "            labels.append(val)\n",
    "            reviews.append(s[:-2])\n",
    "            \n",
    "    return reviews, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Below we define a function gathers the reviews from the file, without cleaning each line, and puts them in two lists based on the class of each review </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_list_uncleaned(*filenames):\n",
    "    labels =[]\n",
    "    reviews = []\n",
    "    for filename in filenames:\n",
    "        for line in open(filename): \n",
    "            val = int(line[-2])\n",
    "            \n",
    "            reviews.append(line.lower()[:-2])\n",
    "            \n",
    "            labels.append(val)\n",
    "            \n",
    "    return reviews, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_train(reviews,labels, Boolean):\n",
    "\n",
    "    #N-gram model that comes up with features or occurances of words\n",
    "    if Boolean == True:\n",
    "        count_vect = CountVectorizer(stop_words='english')\n",
    "        \n",
    "    else:\n",
    "        count_vect = CountVectorizer()\n",
    "    X_train_counts = count_vect.fit_transform(r for r in reviews)\n",
    "    \n",
    "    # This is to scale down impact of tkens that occur very frequently and arent\n",
    "    #very informative.\n",
    "    #Term Frequency time Inverse Document Frequency\n",
    "    \n",
    "    tf_transform = TfidfTransformer()\n",
    "    X_train_tf = tf_transform.fit_transform(X_train_counts)\n",
    "    \n",
    "    #splitting data into test and training sets\n",
    "    X_train, X_test, Y_train, Y_test =train_test_split(X_train_tf,labels, random_state = 35 , train_size =0.90, test_size =0.10)\n",
    " \n",
    "\n",
    "    #MAKING THE MODEL\n",
    "    nb = MultinomialNB()\n",
    "    model = nb.fit(X_train, Y_train)\n",
    "    #array.reshape(-1, 1)\n",
    "    \n",
    "    return nb, tf_transform, count_vect, model, X_test, Y_test\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    " def nb_test(test_file,reviews,labels, Boolean):\n",
    "    nb,tf_transform, count_vect, model, X_test, Y_test = nb_train(reviews,labels, Boolean)\n",
    "   \n",
    "  \n",
    "    \n",
    "    #Now using the test set I need to know if I'm right\n",
    "    test_data = []\n",
    "    for line in open(test_file):\n",
    "        r2 = re.compile(r'[^a-zA-Z0-9]', re.MULTILINE)\n",
    "        s = r2.sub(' ', line)\n",
    "        test_data.append(s)\n",
    "    test_data = stemming(test_data)\n",
    "    test_data = lemming(test_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Making sentiment classification\n",
    "    for i in range (len(test_data)):\n",
    "        X_pred_counts = count_vect.transform(test_data)\n",
    "        X_pred_tf = tf_transform.transform(X_pred_counts)\n",
    "        predictions = nb.predict(X_pred_tf)\n",
    "                \n",
    "                        \n",
    "    #Evaluating the model using the classification report function form sklearn\n",
    "\n",
    "    predicted = model.predict(X_test)    \n",
    "    print(\"The accuracy of this testis: \" ,accuracy_score(Y_test, predicted)*100) \n",
    "\n",
    "    print(\"This is a more detailed report of the classifiers performance: \\n\" ,classification_report(Y_test, predicted))\n",
    "    \n",
    "    return(predictions,\"\\n\")                                                \n",
    "                                                     \n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def stemming(reviews):\n",
    "    lancaster_stemmer = LancasterStemmer()\n",
    "    n_reviews = []\n",
    "    for review in reviews:\n",
    "        n_reviews.append(' '.join(lancaster_stemmer.stem(token)for token in nltk.word_tokenize(review)))\n",
    "    return(n_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemming(reviews):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    n_reviews = []\n",
    "    for review in reviews:\n",
    "        n_reviews.append(' '.join(wordnet_lemmatizer.lemmatize(token)for token in nltk.word_tokenize(review)))\n",
    "    return(n_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_cleaned_data():\n",
    "    reviews, labels = read_file_to_list_cleaned('amazon_cells_labelled.txt', 'imdb_labelled.txt','yelp_labelled.txt')\n",
    "    reviews = stemming(reviews)\n",
    "    reviews = lemming(reviews)\n",
    "\n",
    "    predictions = naiveBayes(reviews,labels,'test_sentences2.txt')\n",
    "    \n",
    "\n",
    "    # write to file to gage my accuracy\n",
    "    with open(\"normalized_results.txt\", \"w+\") as file:\n",
    "        file.write(str(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_NB():\n",
    "    reviews, labels = read_file_to_list_cleaned('amazon_cells_labelled.txt', 'imdb_labelled.txt','yelp_labelled.txt')\n",
    "    reviews = stemming(reviews)\n",
    "    reviews = lemming(reviews)\n",
    "    nb_test('test_sentences2.txt',reviews, labels,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this testis:  80.66666666666666\n",
      "This is a more detailed report of the classifiers performance: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.76      0.80       154\n",
      "          1       0.77      0.86      0.81       146\n",
      "\n",
      "avg / total       0.81      0.81      0.81       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "normalized_NB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalized_NB():\n",
    "    reviews, labels = read_file_to_list_uncleaned('amazon_cells_labelled.txt', 'imdb_labelled.txt','yelp_labelled.txt')\n",
    "    #print(reviews,labels)\n",
    "    nb_test('test_sentences2.txt',reviews, labels, False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this testis:  79.0\n",
      "This is a more detailed report of the classifiers performance: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.78      0.79       154\n",
      "          1       0.77      0.80      0.79       146\n",
      "\n",
      "avg / total       0.79      0.79      0.79       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unnormalized_NB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
